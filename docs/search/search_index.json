{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Harvard Business School runs a computing cluster called the HBS Grid . As of Spring 2021 the HBS Grid has about 620 CPUs, 9 TB of RAM, 200 TB of storage, and high-end GPUs useful for modern deep learning. HBS Research Computing Services is building powerful and user-friendly tools and environments to bring the computing power of the HBS Grid to a wider community of HBS users. Our environments include a wide range of software including Matlab, R, Python, Stata, and hundreds of other popular programs. These environments are in active development and are currently available as a Technology Preview for testing. You can click the video thumbnail below to watch a short demonstration of our software environment. Your browser does not support the video tag. Quicklinks Get started by enabling HBS grid Technology Preview features Start here! Launch Applications from the Desktop Run applications on powerful HBS Grid compute nodes using desktop menus Mount Drives and Copy Data Mount or copy data from local drives or cloud storage to the HBS Grid Share and Collaborate Safely and Securely Learn how to work safely and securely in a multi-user environment Software Applications and Environments Learn about available software and how to run different software versions Start Jobs from the Terminal Run jobs on powerful HBS Grid compute nodes from the terminal Support and Troubleshooting What to do if things don\\'t work as expected User testing and project status We are currently conducting user testing and assessing the possibility of making this software more widely available. The environment is generally stable but the software documented here remains a technology preview and any and all use is at your own risk . If you find that something doesn\\'t work as expected, of if you have a feature request, we would love to know about it so we can fix or improve it. Bug reports and feature requests are important contributions to this project and are always welcome and encouraged! You can either start a discussion at https://github.com/hbs-rcs/hbsgrid-docs/discussions or create an issue report at https://github.com/hbs-rcs/hbsgrid-docs/issues . We are building a friendly and welcoming community of HBS Grid users and we invite you to join us using the links above.","title":"Overview"},{"location":"commandline/","text":"You can use the command line to run large numbers of batch jobs in parallel The HBS Grid uses IBM Spectrum LSF to run applications on powerful remote computers. LSF is a large and complex set of tools; our goal here is to give you just enough information so that you can use it to run jobs on our system, without overwhelming you with details and options. Note This software environment includes robust graphical tools that reduce the need to use the command line for many interactive tasks. This section is for those who prefer the command line, either for aesthetic reasons or because they need to submit batch jobs or carry out complex operations that cannot be easily performed using graphical menu-driven tools. Jobs submission basics LSF provides bsub , a command-line program for running applications on powerful remote computers. For example, you can use bsub -q short_int -Is R to start an interactive R job on a compute node. Breaking this example down will make the basics of bsub clear: bsub ( b atch sub mission) is the top-level command used to run applications on powerful remote machines. -q short_int means you want to run on the short int eractive q ueue (details below). -Is means we are running an I nteractive s hell. The rest of the command ( R in this case) is the command that will be run on the remote machine. Compute cluster basics (click to expand) When you first log in to the HBS Grid using NoMachine or ssh you are running on what we call a \"login node\". The login nodes do not have substantial CPU or RAM available. All computationally intensive processes should be run on what we call \"compute nodes\". A diagram of the HBS Grid architecture helps make this clear: As this diagram shows, the primary purpose of the login nodes is to serve as a hub for launching jobs on powerful compute nodes. You can do that from the command line using bsub or from the desktop menu using application launchers. You may sometimes wish to run applications on the login node, and this is perfectly fine as long as you are not using it for computationally intensive work. For example, you may wish to run python to work out a small code example, or use locate to find a file you were working on. These low-resource activities can and should be done on the login node. The important thing to remember is that bsub is used to run commands on powerful compute nodes. Resource requirements The bsub command allows you to specify RAM and CPU requirements for your job via the -M and -n arguments. For example, you can run a python job with 50 GB of RAM and 4 CPUs with bsub -q short_int -M 50G -n 4 -Is python Knowing just these arguments to bsub will take you a long way. There is much more to know about bsub , but these basics will get you started. Interactive and batch queue limits Machines on the HBS Grid are grouped in queues and bsub can start jobs in either batch (background) or interactive modes. Batch jobs make it easier to run many jobs at once and are more efficient because jobs don't keep running after the program is executed. Interactive jobs on the other hand tend to be more convenient, especially for exploratory work or when developing or debugging a script or program. Batch queues including short and long are for running commands without interaction. For example bsub -q short Rscript my_r_code.R runs my_r_code.R in batch mode, and bsub -q short stata -b my_stata_code.do runs my_stata_code.do in batch mode. Interactive queues like short_int and long_int are used to run applications that you will interact with. For example, bsub -q short_int -Is rstudio runs an interactive RStudio application, and bsub -q short_int -Is xstata runs an interactive Stata application. Info The key differences when submitting batch vs interactive jobs are the -q and -Is arguments. For example we used -q short for batch and -q short_int for interactive. Interactive jobs must also include the -Is option. Queues have other characteristics in addition to the batch vs. interactive distinction. These include the maximum run time and maximum number of CPUs that can be reserved per job. These queue-level limits are summarized in the table below. Queue Type Length Max Cores/Job long_int interactive 3 days 4 short_int interactive 1 day 12 sas_int interactive no limit 4 long batch 7 days 12 short batch 3 days 16 gpu interactive or batch no limit 4 sas batch no limit 4 unlimited interactive or batch no limit 4 Software environments The available software environments contain a huge selection of graphical and terminal-based tools and are described in Software Applications and Environments . For the most part you shouldn't need to do anything to install or configure these tools -- if there is some software you would like that we don't have please get in touch and we'll see if we can install and set it up for you. In order to facilitate reproducible research and analysis we preserve old software environments so that you can switch back to them later if needed. These older environments can be loaded using Lmod . Running ml avail will show you the available environments, named by date and version number. For example, suppose that you have a python project and that your pandas code no longer works with the latest pandas release in the current software environment. In that case you can revert to a previous software environment and run your analysis using an older version of pandas. You can use the ml command from the terminal to list , load , and unload Lmod environment, as shown below. ml avail -------------- /usr/local/app/rcs_bin/techpreview-dev/modulefiles -------------- rcs/rcs_2020.01 (E) rcs/rcs_2021.01 (E) rcs/rcs_2021.03 (E,L,D) Where: D: Default Module E: Technology Preview L: Module is loaded Use \"module spider\" to find all possible modules. Use \"module keyword key1 key2 ...\" to search for all possible modules matching any of the \"keys\". You can get detailed information about specific software modules using the ml spyder command: module spyder rcs/rcs_2021.03 --------------------------------------------------------------------------- rcs: rcs/rcs_2021.03 --------------------------------------------------------------------------- Description: Conda environment for research computing Help: Sets up environment for Data Science and Statistical computing. A huge list of software is avalable, including 'python', 'spyder', 'R', 'rstudio', 'emacs', 'vscode', rclone, ripgrep, nnn and much more. Key software versions: libgcc-ng 9 cudatoolkit 10.1 tensorflow-gpu 2.2 python 3.8 jupyterlab 3.0 numpy 1.20 pandas 1.2 r-base 4.0 r-tidyverse 1.3 sas 9.4 stata 16 octave 6.2 mathematica 12 matlab R2020a emacs 27.1 QGIS 3.16 For a detailed software list open a terminal and run conda env export -n rcs_2021.03 Finally you can use ml to load and unload specific environments. ml rcs_2021.03 will load the rcs_2021.03 environment, and ml -rcs_2021.03 will unload it. Detailed Lmod documentation is available here and you can learn more about the environments available on the HBS Grid in the Environments documentation .","title":"\u2503> &nbsp;Use the Command-line"},{"location":"commandline/#jobs-submission-basics","text":"LSF provides bsub , a command-line program for running applications on powerful remote computers. For example, you can use bsub -q short_int -Is R to start an interactive R job on a compute node. Breaking this example down will make the basics of bsub clear: bsub ( b atch sub mission) is the top-level command used to run applications on powerful remote machines. -q short_int means you want to run on the short int eractive q ueue (details below). -Is means we are running an I nteractive s hell. The rest of the command ( R in this case) is the command that will be run on the remote machine. Compute cluster basics (click to expand) When you first log in to the HBS Grid using NoMachine or ssh you are running on what we call a \"login node\". The login nodes do not have substantial CPU or RAM available. All computationally intensive processes should be run on what we call \"compute nodes\". A diagram of the HBS Grid architecture helps make this clear: As this diagram shows, the primary purpose of the login nodes is to serve as a hub for launching jobs on powerful compute nodes. You can do that from the command line using bsub or from the desktop menu using application launchers. You may sometimes wish to run applications on the login node, and this is perfectly fine as long as you are not using it for computationally intensive work. For example, you may wish to run python to work out a small code example, or use locate to find a file you were working on. These low-resource activities can and should be done on the login node. The important thing to remember is that bsub is used to run commands on powerful compute nodes.","title":"Jobs submission basics"},{"location":"commandline/#resource-requirements","text":"The bsub command allows you to specify RAM and CPU requirements for your job via the -M and -n arguments. For example, you can run a python job with 50 GB of RAM and 4 CPUs with bsub -q short_int -M 50G -n 4 -Is python Knowing just these arguments to bsub will take you a long way. There is much more to know about bsub , but these basics will get you started.","title":"Resource requirements"},{"location":"commandline/#interactive-and-batch-queue-limits","text":"Machines on the HBS Grid are grouped in queues and bsub can start jobs in either batch (background) or interactive modes. Batch jobs make it easier to run many jobs at once and are more efficient because jobs don't keep running after the program is executed. Interactive jobs on the other hand tend to be more convenient, especially for exploratory work or when developing or debugging a script or program. Batch queues including short and long are for running commands without interaction. For example bsub -q short Rscript my_r_code.R runs my_r_code.R in batch mode, and bsub -q short stata -b my_stata_code.do runs my_stata_code.do in batch mode. Interactive queues like short_int and long_int are used to run applications that you will interact with. For example, bsub -q short_int -Is rstudio runs an interactive RStudio application, and bsub -q short_int -Is xstata runs an interactive Stata application. Info The key differences when submitting batch vs interactive jobs are the -q and -Is arguments. For example we used -q short for batch and -q short_int for interactive. Interactive jobs must also include the -Is option. Queues have other characteristics in addition to the batch vs. interactive distinction. These include the maximum run time and maximum number of CPUs that can be reserved per job. These queue-level limits are summarized in the table below. Queue Type Length Max Cores/Job long_int interactive 3 days 4 short_int interactive 1 day 12 sas_int interactive no limit 4 long batch 7 days 12 short batch 3 days 16 gpu interactive or batch no limit 4 sas batch no limit 4 unlimited interactive or batch no limit 4","title":"Interactive and batch queue limits"},{"location":"commandline/#software-environments","text":"The available software environments contain a huge selection of graphical and terminal-based tools and are described in Software Applications and Environments . For the most part you shouldn't need to do anything to install or configure these tools -- if there is some software you would like that we don't have please get in touch and we'll see if we can install and set it up for you. In order to facilitate reproducible research and analysis we preserve old software environments so that you can switch back to them later if needed. These older environments can be loaded using Lmod . Running ml avail will show you the available environments, named by date and version number. For example, suppose that you have a python project and that your pandas code no longer works with the latest pandas release in the current software environment. In that case you can revert to a previous software environment and run your analysis using an older version of pandas. You can use the ml command from the terminal to list , load , and unload Lmod environment, as shown below. ml avail -------------- /usr/local/app/rcs_bin/techpreview-dev/modulefiles -------------- rcs/rcs_2020.01 (E) rcs/rcs_2021.01 (E) rcs/rcs_2021.03 (E,L,D) Where: D: Default Module E: Technology Preview L: Module is loaded Use \"module spider\" to find all possible modules. Use \"module keyword key1 key2 ...\" to search for all possible modules matching any of the \"keys\". You can get detailed information about specific software modules using the ml spyder command: module spyder rcs/rcs_2021.03 --------------------------------------------------------------------------- rcs: rcs/rcs_2021.03 --------------------------------------------------------------------------- Description: Conda environment for research computing Help: Sets up environment for Data Science and Statistical computing. A huge list of software is avalable, including 'python', 'spyder', 'R', 'rstudio', 'emacs', 'vscode', rclone, ripgrep, nnn and much more. Key software versions: libgcc-ng 9 cudatoolkit 10.1 tensorflow-gpu 2.2 python 3.8 jupyterlab 3.0 numpy 1.20 pandas 1.2 r-base 4.0 r-tidyverse 1.3 sas 9.4 stata 16 octave 6.2 mathematica 12 matlab R2020a emacs 27.1 QGIS 3.16 For a detailed software list open a terminal and run conda env export -n rcs_2021.03 Finally you can use ml to load and unload specific environments. ml rcs_2021.03 will load the rcs_2021.03 environment, and ml -rcs_2021.03 will unload it. Detailed Lmod documentation is available here and you can learn more about the environments available on the HBS Grid in the Environments documentation .","title":"Software environments"},{"location":"environments/","text":"This section outlines the software available on the system and shows you how to run specific software versions. Available software A huge range of software applications, utilities, and libraries are installed and configured for you. Whether you need Rstudio or Spyder , Julia running in VSCode , popular R or Python packages, of fully configured Jupyter Notebooks , we have you covered. The list of installed software is so large we make no effort to enumerate everything here, but you can always get an up-to-date list by opening a terminal on the Grid and running conda list Start with the expectation that all the software you need is already installed and ready to use . If that expectation is ever broken please put in a request using our discussion forum or issue tracker . Software environment versions Each time we update our software environments we preserve previous versions so that you can roll back for reproducibility or if your code stops working after an update. This section details the specific software environment versions available. As an illustration of the benefits of preserving historical software environments, imagine that you have a python project and that your Pandas code no longer works with the latest Pandas release in the current software environment. In that case you can start Spyder and revert to a previous software environment in order to run your analysis using an older version of Pandas . The screen-shot below shows how to use the Software environment version selector to run and older version of python . Software environments are named following a rcs_year.version scheme. For example, the first environment released in 2021 is named rcs_2021.01 . The list below shows you key information about each environment, including a command that you can run from the terminal to get a detailed software version list. rcs_2022.01 After more than 6 months of hard work, the HBS grid technology preview software environment version 2022.01 was released in January 2022! This environment remains a technology preview and any and all use is at your own risk . This technology preview software environment is a user-friendly set of software and utilities designed to make data science and statistics easier for HBS Grid users. If you have not yet done so, you can try it by following the quick-start guide . If you are already using the technology preview environment you will be prompted to upgrade next time you log in to the HBS Grid. As always you can continue using previous versions if needed, as described in the environments documentation . In this release we have added a large number of new statistics and data science applications and packages, including: JASP , a free menu-driven statistics application similar to SPSS Cytoscape , an open source software platform for visualizing complex networks, DuckDB , an in-process SQL OLAP database management system texminer , functions for text mining and topic modeling in R Dedupe , a library that uses machine learning to perform de-duplication and entity resolution in Python awscli , a unified tool to manage your AWS services snakemake , a workflow management system to create reproducible and scalable data analyses and many many more! If you find a software program that you need is not yet available please let us know and we will try to install it for you. The 2022.01 release also brings a huge number of application and package updates, including: Python updated to 3.9.9 R updated to 4.1.1 Octave updaed to 6.4 Julia updated to 1.7.1 RStudio updated to 2021.09.1 Spyder updated to 5.2.1 LibreOffice updated to 7.1.8 VSCode updated to 1.63.2 Emacs updated to 27.2 Arrow (C++, R and Python) updated to 6.0 Tensorflow updated to 2.7 PyTorch updated to 1.10.0 CUDA toolkit updated to 11.5.0 Jupyterlab updated to 3.10 MKL updated to 2021.4.0 and hundreds of others. In this release we have also dropped support for several infrequently used programs: OCRfeeder -- use gImageReader for OCR instead Gephi -- replaced by Cytoscape for network visualization PSPP -- replaced by JASP, a modern statistics GUI that uses R under the hood Meld -- use Diffuse for graphical text comparisony Documentation is available on line or via the HBS Grid help application on the Grid. If you have any difficulties or feature requests please reach out on the discussion forum . VirtualBox image available for download from Dropbox and can be imported and run locally for convenience, reproducibility, or testing purposes. For complete environment details, open a terminal and run conda env export -n rcs_2022.01 rcs_2021.06 The rcs_2021.06 environment was released in May 2021. It includes updated Octave , Python , QGIS , R , Stata , and other software. Key software versions included in this environment are listed below. CUDAtoolkit 11.2 Spyder 5.0 Texlive 2021 Emacs 27.2 Julia 1.6.1 Jupyterlab 3.0 Mathematica 12 Matlab R2021a Numpy 1.20 Octave 6.2 Pandas 1.2 Python 3.9 Pytorch 1.8 QGIS 3.18 R 4.0 R-tidyverse 1.3 SAS 9.4 Stata 17 Tensorflow 2.4 For complete environment details, open a terminal and run conda env export -n rcs_2021.06 rcs_2021.03 The rcs_2021.03 environment was released in March 2021. It includes updated Octave , Python , QGIS , R , Stata , and other software. Key software versions included in this environment are listed below. CUDAtoolkit 10.1 Emacs 27.1 Julia 1.5.3 Jupyterlab 3.0 Mathematica 12 Matlab R2020a Numpy 1.20 Octave 6.2 Pandas 1.2 Python 3.8 Pytorch 1.7 QGIS 3.16 R 4.0 R-tidyverse 1.3 SAS 9.4 Stata 16 Tensorflow 2.2 For complete environment details, open a terminal and run conda env export -n rcs_2021.03 rcs_2020.01 The rcs_2020.01 environment was released in March 2020. It includes updated Octave , Python , QGIS , R , Stata , and other software. Key software versions included in this environment are listed below. CUDAtoolkit 10.1 Emacs 27.1 Julia 1.5.3 Jupyterlab 2 Mathematica 12 Matlab R2019a Numpy 1.19 Octave 6.2 Pandas 1.2 Python 3.7 R 3.6 R-tidyverse 1.2 SAS 9.4 Stata 15 Tensorflow 2.2 For complete environment details, open a terminal and run conda env export -n rcs_2020.01","title":"\ud83d\udce6 &nbsp;&nbsp;Use Software Versions"},{"location":"environments/#available-software","text":"A huge range of software applications, utilities, and libraries are installed and configured for you. Whether you need Rstudio or Spyder , Julia running in VSCode , popular R or Python packages, of fully configured Jupyter Notebooks , we have you covered. The list of installed software is so large we make no effort to enumerate everything here, but you can always get an up-to-date list by opening a terminal on the Grid and running conda list Start with the expectation that all the software you need is already installed and ready to use . If that expectation is ever broken please put in a request using our discussion forum or issue tracker .","title":"Available software"},{"location":"environments/#software-environment-versions","text":"Each time we update our software environments we preserve previous versions so that you can roll back for reproducibility or if your code stops working after an update. This section details the specific software environment versions available. As an illustration of the benefits of preserving historical software environments, imagine that you have a python project and that your Pandas code no longer works with the latest Pandas release in the current software environment. In that case you can start Spyder and revert to a previous software environment in order to run your analysis using an older version of Pandas . The screen-shot below shows how to use the Software environment version selector to run and older version of python . Software environments are named following a rcs_year.version scheme. For example, the first environment released in 2021 is named rcs_2021.01 . The list below shows you key information about each environment, including a command that you can run from the terminal to get a detailed software version list.","title":"Software environment versions"},{"location":"environments/#rcs_202201","text":"After more than 6 months of hard work, the HBS grid technology preview software environment version 2022.01 was released in January 2022! This environment remains a technology preview and any and all use is at your own risk . This technology preview software environment is a user-friendly set of software and utilities designed to make data science and statistics easier for HBS Grid users. If you have not yet done so, you can try it by following the quick-start guide . If you are already using the technology preview environment you will be prompted to upgrade next time you log in to the HBS Grid. As always you can continue using previous versions if needed, as described in the environments documentation . In this release we have added a large number of new statistics and data science applications and packages, including: JASP , a free menu-driven statistics application similar to SPSS Cytoscape , an open source software platform for visualizing complex networks, DuckDB , an in-process SQL OLAP database management system texminer , functions for text mining and topic modeling in R Dedupe , a library that uses machine learning to perform de-duplication and entity resolution in Python awscli , a unified tool to manage your AWS services snakemake , a workflow management system to create reproducible and scalable data analyses and many many more! If you find a software program that you need is not yet available please let us know and we will try to install it for you. The 2022.01 release also brings a huge number of application and package updates, including: Python updated to 3.9.9 R updated to 4.1.1 Octave updaed to 6.4 Julia updated to 1.7.1 RStudio updated to 2021.09.1 Spyder updated to 5.2.1 LibreOffice updated to 7.1.8 VSCode updated to 1.63.2 Emacs updated to 27.2 Arrow (C++, R and Python) updated to 6.0 Tensorflow updated to 2.7 PyTorch updated to 1.10.0 CUDA toolkit updated to 11.5.0 Jupyterlab updated to 3.10 MKL updated to 2021.4.0 and hundreds of others. In this release we have also dropped support for several infrequently used programs: OCRfeeder -- use gImageReader for OCR instead Gephi -- replaced by Cytoscape for network visualization PSPP -- replaced by JASP, a modern statistics GUI that uses R under the hood Meld -- use Diffuse for graphical text comparisony Documentation is available on line or via the HBS Grid help application on the Grid. If you have any difficulties or feature requests please reach out on the discussion forum . VirtualBox image available for download from Dropbox and can be imported and run locally for convenience, reproducibility, or testing purposes. For complete environment details, open a terminal and run conda env export -n rcs_2022.01","title":"rcs_2022.01"},{"location":"environments/#rcs_202106","text":"The rcs_2021.06 environment was released in May 2021. It includes updated Octave , Python , QGIS , R , Stata , and other software. Key software versions included in this environment are listed below. CUDAtoolkit 11.2 Spyder 5.0 Texlive 2021 Emacs 27.2 Julia 1.6.1 Jupyterlab 3.0 Mathematica 12 Matlab R2021a Numpy 1.20 Octave 6.2 Pandas 1.2 Python 3.9 Pytorch 1.8 QGIS 3.18 R 4.0 R-tidyverse 1.3 SAS 9.4 Stata 17 Tensorflow 2.4 For complete environment details, open a terminal and run conda env export -n rcs_2021.06","title":"rcs_2021.06"},{"location":"environments/#rcs_202103","text":"The rcs_2021.03 environment was released in March 2021. It includes updated Octave , Python , QGIS , R , Stata , and other software. Key software versions included in this environment are listed below. CUDAtoolkit 10.1 Emacs 27.1 Julia 1.5.3 Jupyterlab 3.0 Mathematica 12 Matlab R2020a Numpy 1.20 Octave 6.2 Pandas 1.2 Python 3.8 Pytorch 1.7 QGIS 3.16 R 4.0 R-tidyverse 1.3 SAS 9.4 Stata 16 Tensorflow 2.2 For complete environment details, open a terminal and run conda env export -n rcs_2021.03","title":"rcs_2021.03"},{"location":"environments/#rcs_202001","text":"The rcs_2020.01 environment was released in March 2020. It includes updated Octave , Python , QGIS , R , Stata , and other software. Key software versions included in this environment are listed below. CUDAtoolkit 10.1 Emacs 27.1 Julia 1.5.3 Jupyterlab 2 Mathematica 12 Matlab R2019a Numpy 1.19 Octave 6.2 Pandas 1.2 Python 3.7 R 3.6 R-tidyverse 1.2 SAS 9.4 Stata 15 Tensorflow 2.2 For complete environment details, open a terminal and run conda env export -n rcs_2020.01","title":"rcs_2020.01"},{"location":"menulaunch/","text":"The HBS Grid makes it easy to run applications with the memory and compute capacity you need for your research. You can run applications on powerful HBS Grid compute nodes by connecting to the HBS grid via NoMachine, enabling technology preview features , and clicking one of the application icons under the Applications or Activities menus. This allows you to easily run compute and/or memory intensive applications with just a few mouse clicks! Basic launcher options Each application will open a dialog where you can configure your environment and resource requirements. Please keep in mind that the system reserves the resources you select, e.g., CPUs used by your job become unavailable for other users. Don't be shy about using resources, but please don't go overboard and reserve way more then you need just because you can. Specific resource requirements depend on the nature of the job, but as a rough guide we recommend requesting RAM 4-10 times the size of your data. For example, if you have a 6 Gb .csv file you may wish to request 24GB of memory or so. The application launchers are meant to be intuitive and easy to use. Most of the fields should be self-explanatory, e.g., there is a numeric field for memory (RAM) in Gigabytes, and another for the number of CPUs needed. As a convenience you can select a starting directory. Click the video thumbnail below to watch an application launcher demonstration: Your browser does not support the video tag. Advanced launcher options If you need to use an older software environment you can do so using the Software environment version dialog. Usually there is no need to use an environment other than the default; the purpose of this mechanism is to give you a fallback in case an update breaks your code, or in case you need to reproduce an old analysis using a specific software environment. As a corollary to that, it is a good idea to note the software environment version when you start a new project so you will know which environment to switch back to if needed. The software and versions available in each environment are documented in Software Applications and Environments . Some application launchers have a Pre-submission command field. This allows you to run an arbitrary bash command immediately before submitting the job. For example, you can use it to set environment variables or activate conda environments . Handling system limits In some cases the desktop launchers will down-grade your request to the maximum available if your request exceeds the system specified limits. There are both user-level, queue-level and job-level limits on the resources that are available to you: You are limited to 3 concurrent interactive jobs. You are limited to a total of 24 CPUs allocated to interactive jobs at any given time. Interactive jobs are limited to 12 CPUs for up to 24 hours, or 4 CPUs for up to 72 hours. As a practical example of these limits, if you try request 12 CPUs and runtime greater than 24 hours the system will not be able to meet your request. In that case it will offer to give you 4 CPUS (the maximum available for jobs running more than 24 hours). More information about queue-level limits can is available in the command line documentation . The HBS grid usually has substantial computational resources available, but sometimes an unusually large number of users are trying to use a lot of resources at the same time. In this case resources may become scarce and you may not be able to access the resources you need. You can get a quick overview of the state of the cluster using the \"HBS Grid available resources utility\", available in the applications menu. This will give you a sense of the current activity on the cluster, and a rough idea of the resources currently available to you. Click the video thumbnail below to watch a demonstration of the available resources utility: Your browser does not support the video tag. Starting batch jobs The graphical menu-based launchers documented in this section are a quick and convenient way to run interactive applications on powerful compute nodes. In the case where you wish to run many such jobs you may find it more convenient to run batch jobs. There is a HBS Grid Batch Submission Utility in the application menu that provides basic batch submission capabilities. For more advanced use refer to the command line documentation .","title":"\ud83d\ude80 &nbsp;&nbsp;Run Desktop Applications"},{"location":"menulaunch/#basic-launcher-options","text":"Each application will open a dialog where you can configure your environment and resource requirements. Please keep in mind that the system reserves the resources you select, e.g., CPUs used by your job become unavailable for other users. Don't be shy about using resources, but please don't go overboard and reserve way more then you need just because you can. Specific resource requirements depend on the nature of the job, but as a rough guide we recommend requesting RAM 4-10 times the size of your data. For example, if you have a 6 Gb .csv file you may wish to request 24GB of memory or so. The application launchers are meant to be intuitive and easy to use. Most of the fields should be self-explanatory, e.g., there is a numeric field for memory (RAM) in Gigabytes, and another for the number of CPUs needed. As a convenience you can select a starting directory. Click the video thumbnail below to watch an application launcher demonstration: Your browser does not support the video tag.","title":"Basic launcher options"},{"location":"menulaunch/#advanced-launcher-options","text":"If you need to use an older software environment you can do so using the Software environment version dialog. Usually there is no need to use an environment other than the default; the purpose of this mechanism is to give you a fallback in case an update breaks your code, or in case you need to reproduce an old analysis using a specific software environment. As a corollary to that, it is a good idea to note the software environment version when you start a new project so you will know which environment to switch back to if needed. The software and versions available in each environment are documented in Software Applications and Environments . Some application launchers have a Pre-submission command field. This allows you to run an arbitrary bash command immediately before submitting the job. For example, you can use it to set environment variables or activate conda environments .","title":"Advanced launcher options"},{"location":"menulaunch/#handling-system-limits","text":"In some cases the desktop launchers will down-grade your request to the maximum available if your request exceeds the system specified limits. There are both user-level, queue-level and job-level limits on the resources that are available to you: You are limited to 3 concurrent interactive jobs. You are limited to a total of 24 CPUs allocated to interactive jobs at any given time. Interactive jobs are limited to 12 CPUs for up to 24 hours, or 4 CPUs for up to 72 hours. As a practical example of these limits, if you try request 12 CPUs and runtime greater than 24 hours the system will not be able to meet your request. In that case it will offer to give you 4 CPUS (the maximum available for jobs running more than 24 hours). More information about queue-level limits can is available in the command line documentation . The HBS grid usually has substantial computational resources available, but sometimes an unusually large number of users are trying to use a lot of resources at the same time. In this case resources may become scarce and you may not be able to access the resources you need. You can get a quick overview of the state of the cluster using the \"HBS Grid available resources utility\", available in the applications menu. This will give you a sense of the current activity on the cluster, and a rough idea of the resources currently available to you. Click the video thumbnail below to watch a demonstration of the available resources utility: Your browser does not support the video tag.","title":"Handling system limits"},{"location":"menulaunch/#starting-batch-jobs","text":"The graphical menu-based launchers documented in this section are a quick and convenient way to run interactive applications on powerful compute nodes. In the case where you wish to run many such jobs you may find it more convenient to run batch jobs. There is a HBS Grid Batch Submission Utility in the application menu that provides basic batch submission capabilities. For more advanced use refer to the command line documentation .","title":"Starting batch jobs"},{"location":"quickstart/","text":"The technology preview software and environments described in this documentation are not enabled on the HBS Grid by default. This guide show you how to connect to the HBS Grid and enable them. Prerequisites Note Skip this section if you are already using the HBS Grid and know how to connect using NoMachine. To get started you must have an HBS Gridaccount and be connected to the HBS network, either directly if you are on-campus or connect via VPN otherwise. You must also have the NoMachine Enterprise Client remote desktop application installed on your computer. Connect and enable software environments Once you have an account and are connected to the HBS network, follow this simple procedure to enable our in-development research computing environment: Example Log in to the HBS Grid by using NoMachine to connect to hosthbsgrid-nx.hbs.edu Open a Terminal in NoMachine: Applications => Favorites => Terminal Run /usr/local/app/rcs_bin/techpreview-dev/enable.sh & exit to open the grid configuration utility (you can copy/paste from the documentation to your Terminal). Select the Technology Preview environment in the welcome dialog and click OK. The video below demonstrates these steps visually. Your browser does not support the video tag. A selection of our most popular applications are available in the favorites list pinned to the task-bar. Additional application launchers can be found in the Applications menu or by searching in Activities. You can add applications to your favorites list by right-clicking and selecting Add to Favorites. Next steps It is our hope that this environment will be intuitive and user-friendly, and you are encouraged to start exploring the available software and tools. If you are doing real work you will probably want to refer to Mount Drives and Copy Data to learn how to get your data onto the HBS Grid. Additional documentation is available if you need it, including the Launch Applications from the Desktop and Start Jobs from the Terminal sections. If you run into any problems please let us know by posting at https://github.com/hbs-rcs/hbsgrid-docs/discussions and letting us know so we can fix them! You may also find the Support and Troubleshooting section helpful.","title":"\u2b8a &nbsp;&nbsp;Get Started"},{"location":"quickstart/#prerequisites","text":"Note Skip this section if you are already using the HBS Grid and know how to connect using NoMachine. To get started you must have an HBS Gridaccount and be connected to the HBS network, either directly if you are on-campus or connect via VPN otherwise. You must also have the NoMachine Enterprise Client remote desktop application installed on your computer.","title":"Prerequisites"},{"location":"quickstart/#connect-and-enable-software-environments","text":"Once you have an account and are connected to the HBS network, follow this simple procedure to enable our in-development research computing environment: Example Log in to the HBS Grid by using NoMachine to connect to hosthbsgrid-nx.hbs.edu Open a Terminal in NoMachine: Applications => Favorites => Terminal Run /usr/local/app/rcs_bin/techpreview-dev/enable.sh & exit to open the grid configuration utility (you can copy/paste from the documentation to your Terminal). Select the Technology Preview environment in the welcome dialog and click OK. The video below demonstrates these steps visually. Your browser does not support the video tag. A selection of our most popular applications are available in the favorites list pinned to the task-bar. Additional application launchers can be found in the Applications menu or by searching in Activities. You can add applications to your favorites list by right-clicking and selecting Add to Favorites.","title":"Connect and enable software environments"},{"location":"quickstart/#next-steps","text":"It is our hope that this environment will be intuitive and user-friendly, and you are encouraged to start exploring the available software and tools. If you are doing real work you will probably want to refer to Mount Drives and Copy Data to learn how to get your data onto the HBS Grid. Additional documentation is available if you need it, including the Launch Applications from the Desktop and Start Jobs from the Terminal sections. If you run into any problems please let us know by posting at https://github.com/hbs-rcs/hbsgrid-docs/discussions and letting us know so we can fix them! You may also find the Support and Troubleshooting section helpful.","title":"Next steps"},{"location":"syncfiles/","text":"You can Copy or move your data to the HBS grid using convenient desktop applications. The HBS Grid is primarily used for data analysis, machine learning, data wrangling, and data visualization. Usually this means that you need to copy or sync your data to the HBS Grid in order to do your work . Access local files from NoMachine login nodes NoMachine makes it easy to mount your local file system on the HBS Grid login node. This is useful for reading documentation, scripts, and other small files without needing to physically copy anything to the HBS Grid. Note that this method will only make files accessible from the login nodes ; for compute node access you will need to copy your files to the HBS grid as described in the next section below Example Follow these simple steps to mount your local file system to the HBS Grid: Log in to the HBS Grid by using NoMachine to connect to host hbsgrid-nx.hbs.edu . Press Ctrl-Alt-0 to open the NoMachine session menu. Click Devices Click Connect a disk . Locate the disk you want to mount under Local disks and click on it. click the Connect button to mount your local disk on the HBS Grid. Click the image below for a local drive mounting demonstration: Your browser does not support the video tag. Sync data from/to local storage NoMachine file mounting is useful, but it has a major limitation; drives mounted via NoMachine are not accessible by applications running on HBS Grid compute nodes . This means that you will usually want to copy or sync your data to the HBS Grid. The easiest way to do this for files on your local machine is to mount your local drive as described above, and then use grsync to sync files from the NoMachine mount to the HBS Grid. Grid storage overview (click here for details) Because you must physically copy data to the HBS Grid in order to access it from the compute nodes , you have to decide where to put it. There are three options:. Home directory A Home directory was created at /export/home/\\ /\\ when you requested your account. Your home folder has limited storage capacity is accessible only by you. Project spaces Project spaces are directories created for particular projects. Project space directories are usually shared and accessible by all HBS Grid users working on that project. You can request a new project space using the new project space request form and you can request modifications to an existing project space using the change request form . See Projects and group membership for details. Scratch storage Files may be temporarily stored in scratch storage, available at /export/scratch. As them name implies, scratch storage is appropriate only for temporary short-term storage. Files stored in /export/scratch and not backed up and will be deleted after 60 days. Scratch storage is a shared resource accessible to all users on the HBS Grid; make sure you set permissions on your files accordingly . Follow these steps to sync data from your local machine to the HBS Grid Log in to the HBS Grid and connect your local drive using NoMachine as described above. Identify the directory on the HBS Grid that you will copy your data too, creating it if needed. From the HBS Grid desktop, open the grsync application. Choose a source directory under the NoMachine mount and specify the target directory from step 2. Click the run button in the upper-right corner of the grsync application. Click the image below for a demonstration showing how to sync your data from a local drive to the HBS Grid: Your browser does not support the video tag. Note that transferring many small files is much slower than transferring a small number of large files. You may find it faster to compress folders with many small files into .zip or .tar archives, transfer those, and decompress/extract them on the other end. Sync data from/to cloud storage (OneDrive,Dropbox etc.) If your data is in cloud storage you may wish to sync it directly from there. While the HBS Grid does not offer native Dropbox , OneDrive , or other cloud storage clients, you can use rclone to perform on-demand data synchronization with all major cloud storage providers. Follow these steps to sync your data from a cloud provider to the HBS Grid: Log in to the HBS Grid and connect your local drive using NoMachine as described above. Identify the directory on the HBS Grid that you will copy your data too, creating it if needed. From the HBS Grid desktop, open the rclone browser application. Click the Config... button and follow the prompts (only needed the first time). Click the cloud storage icon in the Remotes tab and select the directory you wish to sync. Specify the target directory from step 2 in the destination field. Click the image below for a quick demonstration showing how to copy files from Dropbox to the HBS Grid. Your browser does not support the video tag. Help and support If you run into any problems please let us know by posting at https://github.com/hbs-rcs/hbsgrid-docs/discussions and letting us know so we can fix them! You may also find the Support and Troubleshooting section helpful.","title":"\ud83d\uddd8 &nbsp;&nbsp;Copy and Sync Files"},{"location":"syncfiles/#access-local-files-from-nomachine-login-nodes","text":"NoMachine makes it easy to mount your local file system on the HBS Grid login node. This is useful for reading documentation, scripts, and other small files without needing to physically copy anything to the HBS Grid. Note that this method will only make files accessible from the login nodes ; for compute node access you will need to copy your files to the HBS grid as described in the next section below Example Follow these simple steps to mount your local file system to the HBS Grid: Log in to the HBS Grid by using NoMachine to connect to host hbsgrid-nx.hbs.edu . Press Ctrl-Alt-0 to open the NoMachine session menu. Click Devices Click Connect a disk . Locate the disk you want to mount under Local disks and click on it. click the Connect button to mount your local disk on the HBS Grid. Click the image below for a local drive mounting demonstration: Your browser does not support the video tag.","title":"Access local files from NoMachine login nodes"},{"location":"syncfiles/#sync-data-fromto-local-storage","text":"NoMachine file mounting is useful, but it has a major limitation; drives mounted via NoMachine are not accessible by applications running on HBS Grid compute nodes . This means that you will usually want to copy or sync your data to the HBS Grid. The easiest way to do this for files on your local machine is to mount your local drive as described above, and then use grsync to sync files from the NoMachine mount to the HBS Grid. Grid storage overview (click here for details) Because you must physically copy data to the HBS Grid in order to access it from the compute nodes , you have to decide where to put it. There are three options:. Home directory A Home directory was created at /export/home/\\ /\\ when you requested your account. Your home folder has limited storage capacity is accessible only by you. Project spaces Project spaces are directories created for particular projects. Project space directories are usually shared and accessible by all HBS Grid users working on that project. You can request a new project space using the new project space request form and you can request modifications to an existing project space using the change request form . See Projects and group membership for details. Scratch storage Files may be temporarily stored in scratch storage, available at /export/scratch. As them name implies, scratch storage is appropriate only for temporary short-term storage. Files stored in /export/scratch and not backed up and will be deleted after 60 days. Scratch storage is a shared resource accessible to all users on the HBS Grid; make sure you set permissions on your files accordingly . Follow these steps to sync data from your local machine to the HBS Grid Log in to the HBS Grid and connect your local drive using NoMachine as described above. Identify the directory on the HBS Grid that you will copy your data too, creating it if needed. From the HBS Grid desktop, open the grsync application. Choose a source directory under the NoMachine mount and specify the target directory from step 2. Click the run button in the upper-right corner of the grsync application. Click the image below for a demonstration showing how to sync your data from a local drive to the HBS Grid: Your browser does not support the video tag. Note that transferring many small files is much slower than transferring a small number of large files. You may find it faster to compress folders with many small files into .zip or .tar archives, transfer those, and decompress/extract them on the other end.","title":"Sync data from/to local storage"},{"location":"syncfiles/#sync-data-fromto-cloud-storage-onedrivedropbox-etc","text":"If your data is in cloud storage you may wish to sync it directly from there. While the HBS Grid does not offer native Dropbox , OneDrive , or other cloud storage clients, you can use rclone to perform on-demand data synchronization with all major cloud storage providers. Follow these steps to sync your data from a cloud provider to the HBS Grid: Log in to the HBS Grid and connect your local drive using NoMachine as described above. Identify the directory on the HBS Grid that you will copy your data too, creating it if needed. From the HBS Grid desktop, open the rclone browser application. Click the Config... button and follow the prompts (only needed the first time). Click the cloud storage icon in the Remotes tab and select the directory you wish to sync. Specify the target directory from step 2 in the destination field. Click the image below for a quick demonstration showing how to copy files from Dropbox to the HBS Grid. Your browser does not support the video tag.","title":"Sync data from/to cloud storage (OneDrive,Dropbox etc.)"},{"location":"syncfiles/#help-and-support","text":"If you run into any problems please let us know by posting at https://github.com/hbs-rcs/hbsgrid-docs/discussions and letting us know so we can fix them! You may also find the Support and Troubleshooting section helpful.","title":"Help and support"},{"location":"trouble/","text":"The software documented here is under active development and may break or cause other problems . Issue reports and community discussion Bug reports and feature requests are important contributions to this project and are always welcome and encouraged! You can either start a discussion at https://github.com/hbs-rcs/hbsgrid-docs/discussions or create an issue report at https://github.com/hbs-rcs/hbsgrid-docs/issues . We are building a friendly and welcoming community of HBS Grid users and we invite you to join us using the links above. Basic troubleshooting steps If you are experiencing problems with the desktop or application launchers, a good first step is to re-start your desktop using the HBS Grid Configuration utility in the Applications => Accessories menu. If problems persist you can terminate your NoMachine session and start a new one. This will re-initialize your desktop environment and resolve many issues that can occur when your settings get out of sync. Known bugs and work-arounds My application just disappeared! Users are often surprised to find that their application just disappears, often after running for several hours or days. Usually this happens because your application was killed by the system after exceeding a time or memory limit. For example, jobs running in the short interactive queue are limited to a maximum runtime of 24 hours. After 24 hours your job will be killed without warning or notice. Similarly, the system will kill your job if it tries to use more memory than you requested when you started the job. You can avoid having your job killed by staying within the system and job limits. These limits are described in more detail in Handling system limits and Interactive and batch queue limits . Disabling the technology preview If you wish you can disable technology preview features entirely by starting the HBS Grid configuration utility and turning off the technology preview features, as shown below. Selecting the Stable/Standard option under HBS Grid launcher style will mostly restore your system to the original state. To ensure that your environment is completely reset terminate your NoMachine session and start a new one.","title":"\ud83e\uddba &nbsp;&nbsp;Support and Troubleshooting"},{"location":"trouble/#issue-reports-and-community-discussion","text":"Bug reports and feature requests are important contributions to this project and are always welcome and encouraged! You can either start a discussion at https://github.com/hbs-rcs/hbsgrid-docs/discussions or create an issue report at https://github.com/hbs-rcs/hbsgrid-docs/issues . We are building a friendly and welcoming community of HBS Grid users and we invite you to join us using the links above.","title":"Issue reports and community discussion"},{"location":"trouble/#basic-troubleshooting-steps","text":"If you are experiencing problems with the desktop or application launchers, a good first step is to re-start your desktop using the HBS Grid Configuration utility in the Applications => Accessories menu. If problems persist you can terminate your NoMachine session and start a new one. This will re-initialize your desktop environment and resolve many issues that can occur when your settings get out of sync.","title":"Basic troubleshooting steps"},{"location":"trouble/#known-bugs-and-work-arounds","text":"","title":"Known bugs and work-arounds"},{"location":"trouble/#my-application-just-disappeared","text":"Users are often surprised to find that their application just disappears, often after running for several hours or days. Usually this happens because your application was killed by the system after exceeding a time or memory limit. For example, jobs running in the short interactive queue are limited to a maximum runtime of 24 hours. After 24 hours your job will be killed without warning or notice. Similarly, the system will kill your job if it tries to use more memory than you requested when you started the job. You can avoid having your job killed by staying within the system and job limits. These limits are described in more detail in Handling system limits and Interactive and batch queue limits .","title":"My application just disappeared!"},{"location":"trouble/#disabling-the-technology-preview","text":"If you wish you can disable technology preview features entirely by starting the HBS Grid configuration utility and turning off the technology preview features, as shown below. Selecting the Stable/Standard option under HBS Grid launcher style will mostly restore your system to the original state. To ensure that your environment is completely reset terminate your NoMachine session and start a new one.","title":"Disabling the technology preview"},{"location":"worksafe/","text":"The HBS Grid is a multi-user environment shared by many people. Because of this you should ensure that only authorized users can access your files and that you do not monopolize shared resources. Share and Collaborate Safely and Securely Most of us usually work on desktop or laptop computers on which we are the only user, and so these considerations may be new to you. Learning a few simple rules and techniques is needed in order to work safely in our environment. Projects and group membership There are three main locations for storing data on the HBS Grid, as described in Mount Drives and Copy Data . For collaborative projects use a project space ( request one if needed). Each project has an associated group that includes the HBS Grid users who have access to that project space. Changing group membership must currently be done by a system administrator; use the change request form to request a change. File ownership and permissions For project space files you will almost always want group members to have read and write permission. You can view and set permissions using the File Browser or from the command line using the Terminal . Set permissions using the file browser Follow these steps to change file permissions using the *Files( application: Open the Files application from the Applications menu from Activites search Locate the file or folder you wish to modify, right-click on it and select Properties Select the Permissions tab in file properties dialog If you wish to change permissions for all files in a directory, click the Change Permissions for Enclosed Files button. Select appropriate access levels for Owner (you), Group, and Others. Click the image below to see these steps visually: Your browser does not support the video tag. Refer to the Official GNOME documentation for details. Set ownership and permissions using the command line Ownership and permissions can alternatively be set from the command line using chown and chmod . For example chmod -R g+rwx project1/data says \"Recursively for g roup members, add r ead, w rite and e xecute permissions to project1/data and everything in it\". Refer to tldr chmod for more permissions examples and to man chmod for details. Group ownership can be set from the command line using chgrp . For example opening the Terminal application and running chgrp -R my_project_group project1/data says \"Recursively make my_project_group the group owner of project1/data and everything in it\". Refer to tldr chgrp for more examples and to man chgrp for details. Avoid running services like Jupyter notebooks without protection Some applications are designed to run as local servers that you connect to using a web browser or other client. On a single-user machine that may be relatively safe, but in a multi-user environment you need to take extra care to ensure that you don't start services that other users on the HBS Grid can connect to. For example, running an unprotected Jupyter notebook can give other users the ability to connect to your service and execute arbitrary commands as you! Fortunately jupyter notebooks are token protected by default, and you can password protect them if you wish. The key thing is that you must be aware of any services you are running and you must understand how those services are protected against unwanted access by other users on the HBS Grid. The simple rule is if you don't know if or how a service is protected, don't use it !","title":"\ud83d\udc65 &nbsp;&nbsp;Collaborate and Share"},{"location":"worksafe/#share-and-collaborate-safely-and-securely","text":"Most of us usually work on desktop or laptop computers on which we are the only user, and so these considerations may be new to you. Learning a few simple rules and techniques is needed in order to work safely in our environment.","title":"Share and Collaborate Safely and Securely"},{"location":"worksafe/#projects-and-group-membership","text":"There are three main locations for storing data on the HBS Grid, as described in Mount Drives and Copy Data . For collaborative projects use a project space ( request one if needed). Each project has an associated group that includes the HBS Grid users who have access to that project space. Changing group membership must currently be done by a system administrator; use the change request form to request a change.","title":"Projects and group membership"},{"location":"worksafe/#file-ownership-and-permissions","text":"For project space files you will almost always want group members to have read and write permission. You can view and set permissions using the File Browser or from the command line using the Terminal .","title":"File ownership and permissions"},{"location":"worksafe/#set-permissions-using-the-file-browser","text":"Follow these steps to change file permissions using the *Files( application: Open the Files application from the Applications menu from Activites search Locate the file or folder you wish to modify, right-click on it and select Properties Select the Permissions tab in file properties dialog If you wish to change permissions for all files in a directory, click the Change Permissions for Enclosed Files button. Select appropriate access levels for Owner (you), Group, and Others. Click the image below to see these steps visually: Your browser does not support the video tag. Refer to the Official GNOME documentation for details.","title":"Set permissions using the file browser"},{"location":"worksafe/#set-ownership-and-permissions-using-the-command-line","text":"Ownership and permissions can alternatively be set from the command line using chown and chmod . For example chmod -R g+rwx project1/data says \"Recursively for g roup members, add r ead, w rite and e xecute permissions to project1/data and everything in it\". Refer to tldr chmod for more permissions examples and to man chmod for details. Group ownership can be set from the command line using chgrp . For example opening the Terminal application and running chgrp -R my_project_group project1/data says \"Recursively make my_project_group the group owner of project1/data and everything in it\". Refer to tldr chgrp for more examples and to man chgrp for details.","title":"Set ownership and permissions using the command line"},{"location":"worksafe/#avoid-running-services-like-jupyter-notebooks-without-protection","text":"Some applications are designed to run as local servers that you connect to using a web browser or other client. On a single-user machine that may be relatively safe, but in a multi-user environment you need to take extra care to ensure that you don't start services that other users on the HBS Grid can connect to. For example, running an unprotected Jupyter notebook can give other users the ability to connect to your service and execute arbitrary commands as you! Fortunately jupyter notebooks are token protected by default, and you can password protect them if you wish. The key thing is that you must be aware of any services you are running and you must understand how those services are protected against unwanted access by other users on the HBS Grid. The simple rule is if you don't know if or how a service is protected, don't use it !","title":"Avoid running services like Jupyter notebooks without protection"}]}